# Path to models file (optional, defaults to ./models.yaml)
modelsFile: ./models.yaml

# Provider settings
providers:
  openrouter:
    enabled: true
    apiKey: ${OPENROUTER_API_KEY}
    baseUrl: https://openrouter.ai/api/v1
    
  deepseek:
    enabled: true
    apiKey: ${DEEPSEEK_API_KEY}
    baseUrl: https://api.deepseek.com

# Routing settings
routing:
  # Selection algorithm: round-robin (MVP)
  algorithm: round-robin
  
  # Maximum retries on free models
  maxRetries: 3
  
  # Maximum retries on 429 rate limit for one model
  rateLimitRetries: 2
  
  # Delay between retries (ms)
  retryDelay: 1000
  # Note: Jitter Â±20% is hardcoded in RETRY_JITTER_PERCENT constant
  
  # Provider request timeout (ms)
  timeout: 30000
  
  # Fallback to paid model
  fallback:
    enabled: true
    provider: deepseek        # or openrouter
    model: deepseek-chat      # model for fallback

# Circuit Breaker settings (optional, has defaults)
# circuitBreaker:
#   failureThreshold: 3       # Failures to open circuit (default: 3)
#   cooldownPeriod: 60000     # Cooldown in ms (default: 60000 = 1 min)
#   successThreshold: 2       # Successes to close from HALF_OPEN (default: 2)
#   statsWindowSize: 300000   # Statistics window in ms (default: 300000 = 5 min)

# Model priority/weight overrides (optional)
# Allows adjusting priorities without editing models.yaml
# modelOverrides:
#   llama-3.3-70b:
#     priority: 2             # Lower priority (higher number)
#     weight: 5               # Lower weight
#   deepseek-r1:
#     priority: 1             # Higher priority
#     weight: 15              # Higher weight

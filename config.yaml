# Path to models file - can be a local path or HTTP/HTTPS URL
# Examples:
#   modelsFile: ./models.yaml
#   modelsFile: https://example.com/models.yaml
# When using URL, the file is fetched at startup (not saved to disk)
modelsFile: ./models.yaml

# Provider settings
# Note: Use ${ENV_VAR_NAME} to reference any environment variable from .env file
providers:
  openrouter:
    enabled: true
    # API Key for OpenRouter service. Required if OpenRouter is enabled.
    apiKey: ${OPENROUTER_API_KEY}
    # Base URL for OpenRouter (optional, default: https://openrouter.ai/api/v1)
    # baseUrl: https://openrouter.ai/api/v1
    
  deepseek:
    enabled: true
    # API Key for DeepSeek service. Required if DeepSeek is enabled.
    apiKey: ${DEEPSEEK_API_KEY}
    # Base URL for DeepSeek (optional, default: https://api.deepseek.com)
    # baseUrl: https://api.deepseek.com

# Routing settings
routing:
  # Maximum number of model switches (trying different models)
  # When a model fails (5xx, timeout, network error), the router switches to the next model
  maxModelSwitches: 3
  
  # Maximum retries on the same model for temporary errors
  # Applies to: 429 (Rate Limit) and retryable network errors (ENETUNREACH, ECONNRESET)
  maxSameModelRetries: 2
  
  # Delay between retries (ms) - for 429 and network errors on the same model
  retryDelay: 1000
  # Note: Jitter Â±20% is hardcoded in RETRY_JITTER_PERCENT constant
  
  # Provider request timeout in seconds
  timeoutSecs: 30
  
  # Fallback to paid model (single attempt, no retries)
  fallback:
    enabled: true
    provider: deepseek        # or openrouter
    model: deepseek-chat      # model for fallback

# Circuit Breaker settings (optional, has defaults)
# circuitBreaker:
#   failureThreshold: 3       # Failures to open circuit (default: 3)
#   cooldownPeriodMins: 3     # Cooldown in minutes (default: 3 mins)
#   successThreshold: 2       # Successes to close from HALF_OPEN (default: 2)
#   statsWindowSizeMins: 10   # Statistics window in minutes (default: 10 mins)

# Model parameter overrides (optional)
# Allows overriding any model parameters from models.yaml without editing the file
# Available override parameters:
#   - weight: Selection weight (1-100), higher = more likely to be selected
#   - tags: Tags for filtering
#   - contextSize: Context window size in tokens
#   - maxOutputTokens: Maximum output tokens
#   - speedTier: Speed category ('fast' | 'medium' | 'slow')
#   - available: Enable/disable model (true/false)
#   - maxConcurrent: Maximum concurrent requests to this model
# modelOverrides:
#   - name: llama-3.3-70b
#     weight: 5               # Adjust selection probability
#     maxConcurrent: 10       # Limit concurrent requests
#   - name: deepseek-r1
#     provider: deepseek      # Optional: validate provider match
#     weight: 15              # Increase selection probability
#     available: false        # Temporarily disable model
#     speedTier: slow         # Override speed tier
#   - name: qwen-2.5-72b
#     tags: [code, reasoning] # Override tags for filtering
#     contextSize: 32000      # Override context size

# Rate limiting settings (optional, disabled by default)
# rateLimiting:
#   enabled: false            # Enable rate limiting
#   

#   # Per-client limit (by X-Client-ID header or IP)
#   perClient:
#     enabled: true
#     requestsPerMinute: 20   # Max requests per minute per client
#     burstSize: 5            # Extra tokens for burst traffic
#     
#   # Per-model limit (protection against skew)
#   perModel:
#     enabled: true
#     requestsPerMinute: 30   # Max requests per minute per model

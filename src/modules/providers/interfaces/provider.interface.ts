/**
 * Chat message structure
 */
export interface ChatMessage {

  /**
   * Message role
   */
  role: 'system' | 'user' | 'assistant' | 'tool';

  /**
   * Message content
   */
  content: string | null;

  /**
   * Tool calls (for assistant messages)
   */
  tool_calls?: any[];

  /**
   * Tool call ID (for tool messages)
   */
  tool_call_id?: string;
}

/**
 * Chat completion request parameters
 */
export interface ChatCompletionParams {
  /**
   * Model ID to use
   */
  model: string;

  /**
   * Chat messages
   */
  messages: ChatMessage[];

  /**
   * Temperature (0-2)
   */
  temperature?: number;

  /**
   * Maximum tokens to generate
   */
  maxTokens?: number;

  /**
   * Top P sampling
   */
  topP?: number;

  /**
   * Frequency penalty
   */
  frequencyPenalty?: number;

  /**
   * Presence penalty
   */
  presencePenalty?: number;

  /**
   * Stop sequences
   */
  stop?: string | string[];

  /**
   * JSON mode enabled
   */
  jsonMode?: boolean;

  /**
   * Abort signal for request cancellation (graceful shutdown)
   */
  abortSignal?: AbortSignal;

  /**
   * List of tools available to the model
   */
  tools?: any[];

  /**
   * Tool choice constraint
   */
  toolChoice?: string | any;
}

/**
 * Chat completion result
 */
export interface ChatCompletionResult {
  /**
   * Completion ID
   */
  id: string;

  /**
   * Model used
   */
  model: string;

  /**
   * Generated content
   */
  content: string;

  /**
   * Finish reason
   */
  finishReason: 'stop' | 'length' | 'content_filter';

  /**
   * Token usage statistics
   */
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };

  /**
   * Tool calls generated by the model
   */
  toolCalls?: any[];
}

/**
 * LLM provider interface
 */
export interface LlmProvider {
  /**
   * Provider name
   */
  readonly name: string;

  /**
   * Perform chat completion
   */
  chatCompletion(params: ChatCompletionParams): Promise<ChatCompletionResult>;
}

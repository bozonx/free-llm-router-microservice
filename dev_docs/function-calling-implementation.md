# Function Calling Implementation

## Overview

Full OpenAI-compatible function calling (tools) support has been implemented across the microservice and n8n node.

## Architecture

### 1. Microservice Layer

#### DTOs (`src/modules/router/dto/`)

**ChatCompletionRequestDto:**
- `tools?: any[]` - Array of tool definitions
- `tool_choice?: string | any` - Tool selection strategy

**ChatMessageDto:**
- `role` - Extended to support `'tool'`
- `content` - Now `string | null` (null when tool_calls present)
- `tool_calls?: any[]` - Tool invocations from assistant
- `tool_call_id?: string` - Reference to tool call (for tool role)

**ChatCompletionMessage (Response):**
- `content` - Can be `null` when tool_calls present
- `tool_calls?: any[]` - Tool calls in response

#### Provider Interfaces (`src/modules/providers/interfaces/`)

**ChatMessage:**
- Extended with `tool_calls`, `tool_call_id`, and `role: 'tool'`

**ChatCompletionParams:**
- `tools?: any[]` - Tools available to model
- `toolChoice?: string | any` - Tool selection constraint

**ChatCompletionResult:**
- `toolCalls?: any[]` - Tool calls generated by model

#### Providers

**OpenRouterProvider & DeepSeekProvider:**
- Forward `tools` and `tool_choice` to upstream APIs
- Map `tool_calls` from API responses to `ChatCompletionResult`
- Handle `content: null` when tool calls present

#### Services

**RequestBuilderService:**
- Maps tool-related fields from DTO to provider params
- Preserves `tool_calls` and `tool_call_id` in messages

**RouterService:**
- Includes `tool_calls` in final response via `buildSuccessResponse`

### 2. n8n Node Layer

#### FreeLlmRouterChatModel (`n8n-nodes-.../FreeLlmRouterChatModel.ts`)

**Key Methods:**

1. **`bindTools(tools, kwargs)`**
   - LangChain standard method for binding tools to model
   - Creates new instance with tools in `modelKwargs`
   - Returns new `FreeLlmRouterChatModel` instance

2. **`formatMessages(messages)`**
   - Converts LangChain messages to OpenAI format
   - Handles `ToolMessage` with `tool_call_id`
   - Extracts `tool_calls` from AI message `additional_kwargs`
   - Sets `content: null` when tool calls present

3. **`_generate(messages, options, runManager)`**
   - Sends `tools` and `tool_choice` from `modelKwargs` to API
   - Parses `tool_calls` from response
   - Creates `AIMessage` with tool calls in `additional_kwargs`

**LangChain Integration:**
- Fully compatible with LangChain Agents
- Works with `@langchain/core` tools
- Supports tool result feedback loop

## Usage Examples

### Direct API Call

```bash
curl -X POST http://localhost:8080/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What is the weather in London?"}
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_weather",
          "description": "Get current weather",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {"type": "string"}
            }
          }
        }
      }
    ],
    "tool_choice": "auto"
  }'
```

### n8n Workflow

1. Add "Free LLM Router Model" node
2. Add Tool nodes (Calculator, Web Search, etc.)
3. Add "Agent" node
4. Connect model and tools to agent
5. Agent automatically uses `bindTools()` for function calling

## Testing

**E2E Tests:** `test/e2e/function-calling.e2e-spec.ts`
- Validates `tools` and `tool_choice` acceptance
- Validates `tool` role messages
- Ensures no validation errors for function calling fields

**All existing tests pass:** 221 passed, 4 skipped

## Compatibility

- ✅ OpenAI API format
- ✅ LangChain tools
- ✅ n8n Agents
- ✅ Both OpenRouter and DeepSeek providers

## Documentation

- **README.md** - API examples and curl commands
- **n8n README** - Workflow examples
- **CHANGELOG.md** - Release notes
